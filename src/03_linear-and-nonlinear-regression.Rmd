---
title: "Day 3 - Linear and nonlinear regression"
author: "Nayef Ahmad - VCH Decision Support"
date: "November 16, 2018"
output: 
    html_document: 
        toc: yes
        code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE)

library("kableExtra")


# shortcuts: 
# > ctrl + alt + i ==> new code chunk
# > ctrl + shift + k ==> knit doc 
# \  ==> line break (include 2 spaces after)
```


## Load packages for today's session 

```{r}
library(dplyr)  # for manipulating data frames 
library(ggplot2)  # for data viz
library(here)  # for simplifying folder references 
library(readr)  # reading and writing data files 
library(GGally)  # extension to ggplot2
library(ISLR)  # from the book Intro to Stat Learning with R 
library(broom)  # for saving model outputs as dataframes 
library(janitor)  # optional; for cleaning up dataframes 

```

## Motivation for regression models 

Have you ever been asked to ...

* Calculate an average of a variable? *(e.g. ALOS? Avg daily ED visits?)*
* Investigate whether the average of one variable is related to one or more other variables? *(e.g. ALOS by nursing unit? ED visits by time of day?)* 
* Use historical/sample data to make inferences about a population or what might happen in the future? 

If you answered yes to all, regression models may be right for you. 

**A regression models is a quantitative theory of how the mean/expected value of one variable (Y) changes as the values of other variables (X1, x2, ...) change.**

Remember, all models are wrong but some are useful.^[https://en.wikipedia.org/wiki/All_models_are_wrong] Calculating an average was considered cutting-edge modelling in the 16th century.^[https://en.wikipedia.org/wiki/Average#Origin] In a sense, the average is "wrong" because no single data point might actually take the average value.^[https://www.gse.harvard.edu/news/ed/15/08/beyond-average]  

Similarly, regression models simplify away a lot of detail from the raw data. This is a feature, not a bug. 

## Steps in regression modelling 

1) Fit a model
2) Diagnostics: any problems with the model? Is it suitable for the data? 
3) Check overall significance and significance of individual predictors 
4) Check goodness of fit 
5) Fit another model; compare new model with old one, then go with the one that's better (there are algorithmic approaches for making these decisions)


## mtcars example 
Remember this graph? 

```{r}
p1.group.means <- mtcars %>%
    
    # let's recode cyl as a discrete variable: 
    mutate(cyl = factor(cyl, 
                        levels = c(4, 6, 8))) %>% 
    
    # now start using gpplot functions: 
    ggplot(aes(x = disp,  # specify x and y axis
               y = mpg)) + 
    
    geom_point(aes(colour = cyl, 
                   size = hp)) + 
    
    # examine three different ways of summarizing behaviour within
    # each level of cyl: 
    
    # mean by group: 
    stat_smooth(aes(group = cyl,
                    colour = cyl), 
                method = "lm", 
                formula = y ~ 1) + 
    
    theme_classic()
    
# print: 
p1.group.means

```

Two ways to get those horizontal lines: 

### Averages by group: 
```{r}
mtcars %>% 
    group_by(cyl) %>% 
    summarize(mean.mpg = mean(mpg)) %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")
    
    
```


\  
\  
\  

### Regression on categorical variable: 
We use the ```lm``` function to fit a regression model. ```summary``` can be used to examine the model. 

```{r}
df1.mtcars <- mtcars %>% 
    mutate(cyl = as.factor(cyl))

m1.mpg.vs.cyl <- lm(mpg ~ cyl - 1, data = df1.mtcars)

summary(m1.mpg.vs.cyl)


```


### Functions from the package ```broom``` 
The default output is hard to save, so we'll use the ```broom``` package to clean up and create a nice dataframe. 

\  
\  
\  


#### Using ```broom::tidy``` to get model coefficients 

```{r}
#1 row per coefficient 
broom::tidy(m1.mpg.vs.cyl) %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")
    
    



```

\  
\  
\  

#### Using ```broom::glance``` to get one-line model summary 
```{r}
# 1 row per model; very useful when comparing lots of models
broom::glance(m1.mpg.vs.cyl) %>% 
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")

```

\  
\  
\  

#### Using ```broom::augment``` to get predicted values, residuals, etc. 
```{r}
# 1 row per observation
broom::augment(m1.mpg.vs.cyl) %>% 
    head %>% 
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")


```




```{r}
write_csv(broom::tidy(m1.mpg.vs.cyl), 
          here("results", 
               "output from src", 
               "mtcars-regression.csv"))
```

\  
\  
\  


### Interpreting the change in the mean mpg
In both cases above, we see that there's this negative trend: as num cylinders increases, mpg decreases. So what do we gain by doing the regression instead of just calculating averages?

1) Are these "trends" real or are they the result of chance? E.g. is the difference in sample means of 6- and 8- cylinder cars representative of a real difference in the population?

2) Will these "trends" still exist after we account for other variables? We shouldn't just filter out rows based on other variables - we should account for them systematically. 

3) What is the size of the trend (for continuous variables)? Can we compare the trends of two different sites? Can we detect changes in the size of the trend? Can we use the trend to fill in gaps in our knowledge (interpolation and extrapolation)? 


### Averages by group, after accounting for weight
Let's fit another regression, this time incuding weight as a predictor variable. 

```{r}
m2.include.wt <- lm(mpg ~ cyl + wt, data = df1.mtcars)

summary(m2.include.wt)
```

Note that the expected difference in mpg between 4-cylinder and 6-cylinder cars is **4.2556 mpg**, while it was `r 26.6636 - 19.7429` mpg previously. 

Similarly, after accounting for weight, the difference between 6-cylinder cars and 8-cylinder cars is **`r 6.0709-4.2556`** instead of `r 19.7429 - 15.1000`

**This is important. Our conclusions may be biased or irrelevant if we don't systematically control for confounding variables.** E.g. an observed difference in ALOS between two nursing units is almost certainly not due the characteristics of the two nursing units alone - there will be multiple confounding variables such as age, diagnoses, etc.  


#### Diagnostic plots 
Residuals from regression should be white noise with mean zero. This tells you that you have captured all the *systematic* structure in the relationship between the response and the predictor variables, leaving only *randomness/noise*. See [here](http://data.library.virginia.edu/diagnostic-plots/) for more details on interpreting these plots. 


```{r}
# display 4 plots in a 2 by 2 grid: 
par(mfrow = c(2, 2))

plot(m2.include.wt)


```

\  
\  
\  


### Using ```predict``` to interpret models 
Once you fit a model, it exists independently of the data that you started with. This is a powerful abstraction - instead of carrying around raw data to describe a system, you can have a simple mathematical model that is easier to interpret and work with. 

Although you will usually start by looking at regression coefficients, one of the best ways to interpet your model is to kick it and see what it does. In this context, kicking it refers to feeding it an artificial dataset that you create. 

First, just try calling ```predict```: 

```{r}
predict(m2.include.wt)
```

The result is a vector of numbers that gives you the predicted value for each row of the ```mtcars``` dataset. The ```broom::augment``` function is a good way to get these predicted values along with the input data. In the output below, ```.fitted``` gives the value that the regression model predicts, given values of cyl and wt. 

```{r}
augment(m2.include.wt) %>% 
    select(mpg, cyl, wt, .fitted) %>% 
    head(15) %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")
    
```


Let's see how the model uses ```wt``` and ```cyl``` values to predict mpg. We expect three parallel lines, one for each value of cyl, with slope equal to the coefficient of ```wt```. 


```{r}
df1.mtcars %>% 
    mutate(pred.mpg = predict(m2.include.wt)) %>% 
    
    ggplot(aes(x = wt, 
               y = pred.mpg)) + 
    
    geom_point(aes(col = cyl))

```

Yup, just what we expected. Now let's say you have some new data and you want to see what the model predicts for this new data. 

```{r}
# create new fake data: 

df2.mtcars.fake <- data.frame(cyl = as.factor(c(4, 6, 8)), 
                              wt = c(4, 2, 2))

df2.mtcars.fake %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")


```

Now pass the fake data to ```predict```: 

```{r}
# note the "newdata" argument in predict() below

df2.mtcars.fake <- 
    df2.mtcars.fake %>% 
    mutate(pred.mpg = predict(m2.include.wt, 
                              newdata = df2.mtcars.fake)) 

# first plot the points that were originally in the data:  
df1.mtcars %>% 
    mutate(pred.mpg = predict(m2.include.wt)) %>% 
    
    ggplot(aes(x = wt, 
               y = pred.mpg)) + 
    
    geom_point(aes(col = cyl)) + 
    
    # then add the new points. Increase size to make them distinguishable: 
    geom_point(data = df2.mtcars.fake, 
               aes(x = wt, 
                   y = pred.mpg, 
                   col = cyl), 
               size = 5)


```


### Plotting actuals vs predicted values to assess model performance

Plotting the actual values of your response variable vs the predicted values from the model is a great way to see how your model is doing and to compare different models. In the best case scenario, all the points below should fall on the blue line with slope 1 and intercept 0.  

```{r}
augment(m2.include.wt) %>% 
    
    ggplot(aes(x = .fitted, 
               y = mpg)) + 
    
    geom_point(aes(col = cyl)) + 
    
    # add 45 degree line: 
    geom_abline(slope = 1, 
                intercept = 0, 
                col = "blue") + 
    
    # make sure axes have same scale: 
    scale_x_continuous(limits = c(10, 35)) + 
    scale_y_continuous(limits = c(10, 35)) + 
    
    labs(title = "Actuals vs predictions", 
         subtitle = "Points above the line are being under-estimated \nPoints below the line are being over-estimated")
    

```

By building effective models of the way our operations work, we can encapsulate our knowledge succinctly in a form that can immediately answer a lot of important questions. That way, we don't have to keep spending time on surface-level ad hoc analyses that always start from scratch with the raw data ("Let's pull last 2 years of data, make a couple of graphs and send it back to the requester"). **That work has already been done during the modelling process, and does not need to be repeated every time.**   








***********************************************

\  
\  
\  
 
## Mini-Exercise: GDP of US Metro areas 

* Use the ```us-msa-gdp-and-population.csv``` dataset to find the relationship between GDP (in millions of USD) and population for US metropolitan statistical areas (MSAs). 
* How can you tell whether a particular MSA is under-performing or over-performing, relative to its population size? 
* Identify the top 3 over-performing MSAs. 


***********************************************

\  
\  
\  


## Transformations of variables and interactions between variables 
We worked with a log-transformation in the mini-exercise. Now let's look at interactions between variables. These examples are from ISLR.^[https://www-bcf.usc.edu/~gareth/ISL/]  



### Interaction between 2 continuous variables.  

First read in the data:  

```{r}
df2.advert <- read_csv(here::here("data", 
                                  "Advertising.csv")) %>% 
    select(-X1) %>%  # drop unnecessary column 
    clean_names  # from "janitor"" package

# str(df2.advert)
# summary(df2.advert)
# head(df2.advert)

```


First we'll fit a model without an interaction: 

```{r}
m3.advert.no.interaction <- lm(sales ~ tv + radio, 
                               data = df2.advert)

# summary(m3.advert.no.interaction)


# look at model coefficients 
tidy(m3.advert.no.interaction) %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")

# model summary: 
glance(m3.advert.no.interaction) %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")
    
    

```

```{r}
# look at residual plots:
par(mfrow = c(2, 2))  # plot 4 graphs on 1 screen
plot(m3.advert.no.interaction)

```

Those curved shapes on the top-left and bottom-left plots are a little worrying. Looks like we're under-predicting sales both at the lower end of the range and the higher end. 

What if we add an interaction term? We see that the effect of tv advertising on sales is *dependent on the level of radio advertising*.  

```{r}
m4.advert.with.interact <- lm(sales ~ tv + 
                                  radio + 
                                  tv*radio,  # interaction term
                              data = df2.advert)

# summary(m4.advert.with.interact)


# look at model coefficients 
tidy(m4.advert.with.interact) %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")

# model summary: 
glance(m4.advert.with.interact) %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")


# residual plots 
par(mfrow = c(2, 2))  # plot 4 graphs on 1 screen
plot(m4.advert.with.interact)

```

### Mini-exercise: explore interaction with ```predict``` 
Set up a fake dataset to explore how the interaction between tv and radio advertising works. For example, try creating a dataframe with four rows: 

* Rows 1 and 2: keep tv at a fixed value, but create two values of radio that differ by 1 unit. 
* Rows 3 and 4: Change the value of tv, but keep it constant across Rows 3 and 4. Leave the values of radio as in the previous two rows. 

Then pass this fake data to the ```predict``` function. K


\  
\  
\  

### Interaction between continuous and categorical variables 
We'll use the ```Credit``` dataset. The goal is to predict the balance on a customer's credit card.  

```{r}
df3.credit <- Credit %>% 
    clean_names()

# str(df3.credit)
# summary(df3.credit)
head(df3.credit) %>% 
    
    # don't use these lines; they're only for RMarkdown docs: 
    kable() %>% 
    kable_styling(bootstrap_options = c("striped",
                                        "condensed", 
                                        "responsive"), 
                  full_width = FALSE, 
                  position = "left")
    

```


First fit a model with only income and student. 
```{r}
m5.credit <- lm(balance ~ income + student, 
                data = df3.credit)

# summary(m5.credit)

df3.credit %>%  
    mutate(pred.balance = predict(m5.credit)) %>% 
    
    ggplot(aes(x = income, 
               y = pred.balance)) + 
    
    geom_point(aes(col = student))


```

Does it make sense that the effect of additional income is the same whether or not you're a student? Possibly not. Let's fit a more general model that does allow for the slope of the 2 lines to differ. 


```{r}

m6.credit.interact <- lm(balance ~ income +
                             student + 
                             income*student,  # interaction term
                         data = df3.credit)

summary(m6.credit.interact)

df3.credit %>%  
    mutate(pred.balance = predict(m6.credit.interact)) %>% 
    
    ggplot(aes(x = income, 
               y = pred.balance)) + 
    
    geom_point(aes(col = student))



```

Note that adjusted R-squared and Residual standard error are pretty much exactly the same after adding the interaction, and the interaction is not significant. In this case, we should exclude the interaction from our final model. 





***********************************************

\  
\  
\  


## Boston house prices dataset 
Use the Boston dataset from the ISLR package. Try to find the best model to predict median house value (```medv```) using the 13 other variables in the dataset. 



***********************************************

\  
\  
\  



## Footnotes 


